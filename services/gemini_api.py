import google.generativeai as genai
import logging
import os
import json
import re
from dotenv import load_dotenv

# Loglama ayarlarÄ±
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

load_dotenv()

GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')

def extract_json_from_response(text):
    """
    CÃ¼mleler iÃ§inden sadece JSON kÄ±smÄ±nÄ± Ã§Ä±karÄ±r
    """
    try:
        # Metin iÃ§indeki ilk { ile son } arasÄ±nÄ± bul
        match = re.search(r'{.*}', text, re.DOTALL)
        if match:
            json_text = match.group(0)
            return json.loads(json_text)
        else:
            raise ValueError("JSON formatÄ± bulunamadÄ±")
    except Exception as e:
        raise ValueError(f"JSON Ã§Ä±karma hatasÄ±: {str(e)}")

class GeminiAPI:
    def __init__(self):
        try:
            # API anahtarÄ±nÄ±n varlÄ±ÄŸÄ±nÄ± kontrol et
            if not GOOGLE_API_KEY:
                raise ValueError("GOOGLE_API_KEY is not set in .env file")
                
            # API anahtarÄ±nÄ±n formatÄ±nÄ± kontrol et
            if not GOOGLE_API_KEY.startswith('AIza'):
                raise ValueError("Invalid API key format. It should start with 'AIza'")
                
            genai.configure(api_key=GOOGLE_API_KEY)
            logger.info(f"Configured API with key: {GOOGLE_API_KEY[:5]}...{GOOGLE_API_KEY[-5:]}")
            
            # Modeli oluÅŸtur
            try:
                # Hikaye oluÅŸturma iÃ§in model
                self.story_model = genai.GenerativeModel("gemini-1.5-flash")
                # DeÄŸerlendirme iÃ§in model
                self.evaluation_model = genai.GenerativeModel("gemini-1.5-flash")
                logger.info("Created Gemini model instances")
                
                # Modelin Ã§alÄ±ÅŸÄ±p Ã§alÄ±ÅŸmadÄ±ÄŸÄ±nÄ± test et
                test_prompt = "Test prompt"
                test_response = self.story_model.generate_content(test_prompt)
                logger.info("Test model response successful")
                
                # Prompt ÅŸablonlarÄ±nÄ± yÃ¼kle
                self.load_prompt_templates()
                
            except Exception as e:
                logger.error(f"Error creating or testing model: {str(e)}")
                raise ValueError(f"Failed to create or test model: {str(e)}")
            
        except Exception as e:
            logger.error(f"Initialization error: {str(e)}")
            raise ValueError(f"Failed to initialize Gemini API: {str(e)}")
            
    def load_prompt_templates(self):
        """Prompt ÅŸablonlarÄ±nÄ± yÃ¼kler"""
        try:
            # Hikaye oluÅŸturma ÅŸablonu
            with open("data/dynamic_prompt_template.json", "r", encoding="utf-8") as f:
                self.story_template = json.load(f)["prompt_template"]
            logger.info("Loaded story prompt template")
            
            # DeÄŸerlendirme ÅŸablonu
            with open("data/evaluate_prompt_template.json", "r", encoding="utf-8") as f:
                self.evaluation_template = json.load(f)["prompt_template"]
            logger.info("Loaded evaluation prompt template")
            
        except Exception as e:
            logger.error(f"Error loading prompt templates: {str(e)}")
            raise ValueError(f"Failed to load prompt templates: {str(e)}")

    def generate_story(self, data):
        """
        Ä°lk LLM: Ã–ÄŸrencinin evren, konu ve sÄ±nÄ±f seviyesine gÃ¶re hikaye ve sorular oluÅŸturur
        """
        try:
            # Gerekli verilerin varlÄ±ÄŸÄ±nÄ± kontrol et
            required_fields = ['level', 'universe', 'topic']
            for field in required_fields:
                if field not in data:
                    raise ValueError(f"Missing required field: {field}")
            
            # Prompt ÅŸablonunu doldur
            prompt = self.story_template.replace("{{evren}}", data['universe'])\
                                      .replace("{{konu}}", data['topic'])\
                                      .replace("{{seviye}}", data['level'])
            
            logger.info(f"Generating story with prompt: {prompt[:50]}...")
            
            # Ä°Ã§erik Ã¼ret
            try:
                response = self.story_model.generate_content(prompt)
                logger.info("Successfully generated story content")
            except Exception as e:
                logger.error(f"Error generating story content: {str(e)}")
                raise ValueError(f"Failed to generate story content: {str(e)}")
            
            # CevabÄ± dÃ¶ndÃ¼r ve iÅŸle
            try:
                if hasattr(response, 'text'):
                    raw_text = response.text
                    logger.info(f"Raw response: {raw_text[:100]}...")
                    
                    # JSON formatÄ±na dÃ¶nÃ¼ÅŸtÃ¼r
                    parsed_json = extract_json_from_response(raw_text)
                    logger.info(f"Successfully parsed JSON content")
                    
                    # Ã‡Ä±ktÄ±yÄ± yapÄ±landÄ±r (gÃ¶rsel fikri kaldÄ±rÄ±ldÄ±)
                    output_data = {
                        "universe": data['universe'],
                        "topic": data['topic'],
                        "level": data['level'],
                        "story": parsed_json.get("story", ""),
                        "quiz": parsed_json.get("quiz", [])
                    }
                    
                    # Ã‡Ä±ktÄ±yÄ± JSON dosyasÄ±na kaydet (ikinci LLM iÃ§in bellek olarak)
                    self.save_output_to_file(output_data)
                    
                    return output_data
                else:
                    raise Exception("AI cevabÄ± geÃ§ersiz")
            
            except Exception as e:
                logger.error(f"Error processing story response: {str(e)}")
                logger.error(f"Response object: {str(response)}")
                raise ValueError(f"Invalid story response format: {str(e)}")

        except Exception as e:
            logger.error(f"Error in generate_story: {str(e)}")
            raise ValueError(f"Failed to generate story: {str(e)}")
    
    def save_output_to_file(self, output_data):
        """Ã‡Ä±ktÄ±yÄ± JSON dosyasÄ±na kaydeder (ikinci LLM iÃ§in bellek)"""
        try:
            with open("data/last_story_output.json", "w", encoding="utf-8") as f:
                json.dump(output_data, f, indent=4, ensure_ascii=False)
            logger.info("Saved story output to file for future reference")
        except Exception as e:
            logger.error(f"Error saving output to file: {str(e)}")
    
    def evaluate_answers(self, answers):
        """
        Ä°kinci LLM: Ã–ÄŸrencinin cevaplarÄ±nÄ± deÄŸerlendirir
        """
        try:
            # Son hikaye Ã§Ä±ktÄ±sÄ±nÄ± yÃ¼kle (ikinci LLM iÃ§in bellek)
            try:
                with open("data/last_story_output.json", "r", encoding="utf-8") as f:
                    story_data = json.load(f)
                logger.info("Loaded previous story data for evaluation context")
            except Exception as e:
                logger.error(f"Error loading story data: {str(e)}")
                story_data = {"universe": "Bilinmiyor", "topic": "Bilinmiyor", "level": "Bilinmiyor"}
            
            # SorularÄ± ve cevaplarÄ± birleÅŸtir
            sorular_ve_cevaplar = ""
            quiz = story_data.get("quiz", [])
            
            for i, (question, answer) in enumerate(zip(quiz, answers.values()), 1):
                soru_metni = question.get("question", f"Soru {i}")
                sorular_ve_cevaplar += f"Soru {i}: {soru_metni}\nCevabÄ±n: {answer}\n\n"
            
            # DeÄŸerlendirme ÅŸablonunu doldur
            eval_prompt = self.evaluation_template\
                .replace("{{evren}}", story_data.get("universe", "Bilinmiyor"))\
                .replace("{{konu}}", story_data.get("topic", "Bilinmiyor"))\
                .replace("{{seviye}}", story_data.get("level", "Bilinmiyor"))\
                .replace("{{sorular_ve_cevaplar}}", sorular_ve_cevaplar)
            
            logger.info(f"Evaluating answers with prompt: {eval_prompt[:100]}...")
            
            # DeÄŸerlendirme yap
            try:
                response = self.evaluation_model.generate_content(eval_prompt)
                logger.info("Successfully generated evaluation")
            except Exception as e:
                logger.error(f"Error generating evaluation: {str(e)}")
                raise ValueError(f"Failed to generate evaluation: {str(e)}")
            
            # DeÄŸerlendirme sonucunu dÃ¶ndÃ¼r
            if hasattr(response, 'text'):
                evaluation_text = response.text
                logger.info(f"Evaluation response: {evaluation_text[:100]}...")
                return evaluation_text
            else:
                raise Exception("AI deÄŸerlendirme cevabÄ± geÃ§ersiz")
                
        except Exception as e:
            logger.error(f"Error in evaluate_answers: {str(e)}")
            raise ValueError(f"Failed to evaluate answers: {str(e)}")
    
    def generate_content(self, data):
        """
        Geriye dÃ¶nÃ¼k uyumluluk iÃ§in eski fonksiyonu koruyoruz
        """
        return self.generate_story(data)


if __name__ == '__main__':
    api = GeminiAPI()
    
    # Test hikaye oluÅŸturma
    test_data = {
        'universe': 'Minecraft',
        'topic': 'Enerji dÃ¶nÃ¼ÅŸÃ¼mÃ¼',
        'level': '6'
    }
    
    try:
        # Hikaye oluÅŸtur
        story_result = api.generate_story(test_data)
        print("\nðŸ§  Hikaye Sonucu:\n")
        print(json.dumps(story_result, indent=4, ensure_ascii=False))
        
        # Test cevaplarÄ± deÄŸerlendir
        test_answers = {
            'cevap1': 'Demir cevherini eritmek iÃ§in.',
            'cevap2': 'IsÄ± enerjisi barÄ±ndÄ±rÄ±r. Su ile temas edince obsidyen oluÅŸur.',
            'cevap3': 'Kimyasal enerji Ä±ÅŸÄ±k enerjisine dÃ¶nÃ¼ÅŸÃ¼r.'
        }
        
        evaluation_result = api.evaluate_answers(test_answers)
        print("\nðŸ“Š DeÄŸerlendirme Sonucu:\n")
        print(evaluation_result)
        
    except Exception as e:
        print("Error:", str(e))
